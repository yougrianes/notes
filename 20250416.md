“End-to-End Driving with Online Trajectory Evaluation via BEV World Model”一文提出了基于鸟瞰图（BEV）世界模型的端到端自动驾驶轨迹评估框架WoTE，利用BEV世界模型预测未来BEV状态来评估轨迹，在相关基准测试中取得了优异性能。

1. **研究背景**：端到端自动驾驶将感知、预测和规划集成到一个可微框架中取得进展，但有效在线轨迹评估对保障安全至关重要。传统轨迹评估方法基于规则，对感知误差敏感且难以端到端优化；现有的端到端驾驶方法仅基于当前状态评估轨迹，缺乏对未来状态的考量。
2. **相关工作**
    - **端到端自动驾驶**：分为基于模仿学习和强化学习两类。模仿学习通过专家轨迹监督预测轨迹；强化学习利用环境动态建模来优化策略，还有结合两者的方法。
    - **轨迹评估**：分为无模型和有模型方法。无模型方法直接用观测数据评估策略；有模型方法借助世界模型捕捉环境动态进行更准确的策略评估，但现有有模型方法存在依赖显式轨迹表示和不可微指标的问题。
3. **方法**：WoTE包含轨迹预测器、BEV世界模型、奖励模型和BEV空间监督四个关键组件。
    - **轨迹预测器**：多模态BEV编码器将多模态传感器输入（LiDAR和多视图RGB图像）编码为统一的BEV特征图；通过K-Means聚类生成轨迹锚；轨迹细化模块基于BEV特征图和轨迹锚预测细化轨迹。
    - **BEV世界模型**：将当前BEV状态和细化轨迹组合成状态 - 动作对作为输入，通过Transformer编码器架构的世界模型以循环方式预测未来多步的BEV状态和动作。
    - **奖励模型**：包含模仿奖励和模拟奖励。模仿奖励衡量预测轨迹与专家轨迹的相似性；模拟奖励基于模拟器定义的标准评估轨迹质量。奖励模型基于当前和未来BEV状态预测每条轨迹的奖励，选择奖励最高的轨迹作为最终轨迹。
    - **BEV空间监督**：利用nuPlan等BEV空间交通模拟器生成的BEV语义图和奖励进行监督。包括对BEV状态的监督（使用Focal Loss）、模拟奖励的监督（使用二元交叉熵损失）、模仿奖励的监督（使用交叉熵损失）以及对轨迹的监督（采用winner-take-all策略和L1损失），总训练损失为各项损失之和。
4. **实验**
    - **基准测试**：使用NAVSIM数据集和Bench2Drive基准进行评估。NAVSIM数据集基于nuPlan构建，包含具有挑战性的驾驶场景，采用预测驾驶员模型得分（PDMS）等指标评估模型性能；Bench2Drive基准基于CARLA模拟器，采用驾驶得分（DS）和成功率作为评估指标。
    - **实现细节**：在NAVSIM实验中，设置输入数据、网络架构、轨迹锚数量、奖励权重等参数进行训练和测试；在Bench2Drive实验中，以TCP为基线，调整训练策略进行实验。
    - **对比SOTA**：在NAVSIM和Bench2Drive基准测试中，WoTE均优于其他方法，证明了其有效性。
    - **消融研究**：验证了轨迹评估和未来状态预测、模仿和模拟奖励、循环未来状态预测以及轨迹数量对模型性能的影响，并分析了模型的延迟和泛化能力。
    - **可视化分析**：通过可视化端到端规划轨迹和轨迹奖励，展示了WoTE在过滤低质量轨迹和合理评估轨迹方面的优势。
5. **研究结论**：提出的WoTE框架利用BEV世界模型实现了更有效的端到端轨迹评估，在相关基准测试中达到了最先进的性能，同时保持了实时效率，为端到端在线轨迹评估提供了重要的研究方向。
6. **创新点**
    - **引入BEV世界模型**：在端到端自动驾驶中利用BEV世界模型预测未来状态，考虑了驾驶场景的动态演变，提升了轨迹评估的有效性。
    - **解决监督难题**：通过BEV空间监督，利用BEV空间交通模拟器提供的语义未来状态和规则奖励目标，解决了未来状态监督困难的问题。
    - **高效实时预测**：BEV空间的信息紧凑性使得模型能够进行高效的单步前馈未来预测，满足实时驾驶应用的需求。
7. **深入挖掘空间**
    - **模型优化**：进一步优化BEV世界模型和奖励模型的结构，探索更高效的网络架构，提高模型的性能和效率。
    - **场景拓展**：在更多复杂和多样化的驾驶场景中进行实验和验证，提升模型的泛化能力和适应性。
    - **多模态融合**：探索更有效的多模态融合方式，充分利用传感器数据的信息，提高模型对环境的感知和理解能力。
